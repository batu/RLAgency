{
    "name": "root",
    "gauges": {
        "Basic.Policy.Entropy.mean": {
            "value": 1.1190204620361328,
            "min": 1.1190204620361328,
            "max": 1.4192990064620972,
            "count": 102
        },
        "Basic.Policy.Entropy.sum": {
            "value": 11208.1083984375,
            "min": 11174.1015625,
            "max": 14215.69921875,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.10765378922224045,
            "min": 0.007605706807225943,
            "max": 0.13323429226875305,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.sum": {
            "value": 364.3004150390625,
            "min": 25.517147064208984,
            "max": 450.46514892578125,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.mean": {
            "value": 86.92173913043479,
            "min": 74.55833333333334,
            "max": 255.0,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.sum": {
            "value": 9996.0,
            "min": 8160.0,
            "max": 12165.0,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.mean": {
            "value": 0.9655991896824992,
            "min": -0.2490234375,
            "max": 1.1083411586610235,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.sum": {
            "value": 111.04390681348741,
            "min": -10.854249753057957,
            "max": 144.56893048621714,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.mean": {
            "value": 0.9655991896824992,
            "min": -0.2490234375,
            "max": 1.1083411586610235,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.sum": {
            "value": 111.04390681348741,
            "min": -10.854249753057957,
            "max": 144.56893048621714,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.mean": {
            "value": 0.04562869807813286,
            "min": 0.03788212294178568,
            "max": 0.059522069295780966,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.sum": {
            "value": 0.13688609423439857,
            "min": 0.07576424588357136,
            "max": 0.16343076132003867,
            "count": 102
        },
        "Basic.Losses.ValueLoss.mean": {
            "value": 0.006665726800242231,
            "min": 1.877684787151187e-05,
            "max": 0.01019487112595622,
            "count": 102
        },
        "Basic.Losses.ValueLoss.sum": {
            "value": 0.019997180400726695,
            "min": 3.755369574302374e-05,
            "max": 0.029311811405932527,
            "count": 102
        },
        "Basic.Policy.LearningRate.mean": {
            "value": 2.7751967312174505e-06,
            "min": 2.7751967312174505e-06,
            "max": 0.00029817890685703127,
            "count": 102
        },
        "Basic.Policy.LearningRate.sum": {
            "value": 8.325590193652352e-06,
            "min": 8.325590193652352e-06,
            "max": 0.0008781468822843749,
            "count": 102
        },
        "Basic.Policy.Epsilon.mean": {
            "value": 0.10092503255208334,
            "min": 0.10092503255208334,
            "max": 0.19939296875,
            "count": 102
        },
        "Basic.Policy.Epsilon.sum": {
            "value": 0.30277509765625,
            "min": 0.20385380859375002,
            "max": 0.5927156250000001,
            "count": 102
        },
        "Basic.Policy.Beta.mean": {
            "value": 5.61591243489584e-05,
            "min": 5.61591243489584e-05,
            "max": 0.0049697091406250005,
            "count": 102
        },
        "Basic.Policy.Beta.sum": {
            "value": 0.0001684773730468752,
            "min": 0.0001684773730468752,
            "max": 0.0146365096875,
            "count": 102
        },
        "Basic.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        },
        "Basic.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1618318021",
        "python_version": "3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\user\\Anaconda3\\envs\\rlnav\\Scripts\\mlagents-learn rlnav/configs/PPO.yaml --env=C:\\Users\\user\\Desktop\\RLNav\\NavigationEnvironments\\P0\\Jump\\Env.exe --run-id=0_Pipeline\\Jump\\PPO\\Run_8 --time-scale=10 --base-port=6408 --width=480 --height=480",
        "mlagents_version": "0.25.0",
        "mlagents_envs_version": "0.25.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.8.1+cpu",
        "numpy_version": "1.19.5",
        "end_time_seconds": "1618321974"
    },
    "total": 3953.2047837,
    "count": 1,
    "self": 2.520332900000085,
    "children": {
        "run_training.setup": {
            "total": 0.26270950000000015,
            "count": 1,
            "self": 0.26270950000000015
        },
        "TrainerController.start_learning": {
            "total": 3950.4217413,
            "count": 1,
            "self": 3.69797699992705,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.9594344999999995,
                    "count": 1,
                    "self": 6.9594344999999995
                },
                "TrainerController.advance": {
                    "total": 3939.5625203000727,
                    "count": 69256,
                    "self": 3.5140893000307187,
                    "children": {
                        "env_step": {
                            "total": 2146.35350100001,
                            "count": 69256,
                            "self": 2027.8267070999775,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 116.40178230001081,
                                    "count": 69256,
                                    "self": 8.815618399984288,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 107.58616390002652,
                                            "count": 64002,
                                            "self": 18.454221599986482,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 89.13194230004004,
                                                    "count": 64002,
                                                    "self": 89.13194230004004
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 2.125011600021722,
                                    "count": 69256,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3938.9735409000264,
                                            "count": 69256,
                                            "is_parallel": true,
                                            "self": 2140.480893299983,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0014733000000006768,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00045600000000156626,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0010172999999991106,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0010172999999991106
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 1798.4911743000434,
                                                    "count": 69256,
                                                    "is_parallel": true,
                                                    "self": 12.720888700083833,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 140.43225950002088,
                                                            "count": 69256,
                                                            "is_parallel": true,
                                                            "self": 140.43225950002088
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 1579.0231240999847,
                                                            "count": 69256,
                                                            "is_parallel": true,
                                                            "self": 1579.0231240999847
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 66.31490199995415,
                                                            "count": 69256,
                                                            "is_parallel": true,
                                                            "self": 19.189328399970634,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 47.12557359998351,
                                                                    "count": 138512,
                                                                    "is_parallel": true,
                                                                    "self": 47.12557359998351
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1789.6949300000317,
                            "count": 69256,
                            "self": 3.3985157999888997,
                            "children": {
                                "process_trajectory": {
                                    "total": 1148.7588608000433,
                                    "count": 69256,
                                    "self": 1148.3677070000433,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.3911537999999837,
                                            "count": 2,
                                            "self": 0.3911537999999837
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 637.5375533999995,
                                    "count": 249,
                                    "self": 427.43711470001057,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 210.10043869998896,
                                            "count": 11952,
                                            "self": 210.10043869998896
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.8000004022032954e-06,
                    "count": 1,
                    "self": 2.8000004022032954e-06
                },
                "TrainerController._save_models": {
                    "total": 0.2018066999999064,
                    "count": 1,
                    "self": 0.038435500000105094,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.16337119999980132,
                            "count": 1,
                            "self": 0.16337119999980132
                        }
                    }
                }
            }
        }
    }
}