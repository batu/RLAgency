{
    "name": "root",
    "gauges": {
        "Basic.Policy.Entropy.mean": {
            "value": 1.3643120527267456,
            "min": 1.364187479019165,
            "max": 1.424309253692627,
            "count": 102
        },
        "Basic.Policy.Entropy.sum": {
            "value": 13403.001953125,
            "min": 11574.10546875,
            "max": 17429.7421875,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.mean": {
            "value": 167.84745762711864,
            "min": 140.59154929577466,
            "max": 255.0,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.sum": {
            "value": 9903.0,
            "min": 7720.0,
            "max": 12240.0,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.061196278780698776,
            "min": -0.012883367016911507,
            "max": 0.07359859347343445,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3.6105804443359375,
            "min": -0.5153346657752991,
            "max": 5.098456859588623,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.mean": {
            "value": 0.25952370363776966,
            "min": -0.2490234375,
            "max": 0.40588583030870984,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.sum": {
            "value": 15.31189851462841,
            "min": -9.7119140625,
            "max": 28.412008121609688,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.mean": {
            "value": 0.25952370363776966,
            "min": -0.2490234375,
            "max": 0.40588583030870984,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.sum": {
            "value": 15.31189851462841,
            "min": -9.7119140625,
            "max": 28.412008121609688,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.mean": {
            "value": 0.029231520003425736,
            "min": 0.02332192616692434,
            "max": 0.04670416878555746,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.sum": {
            "value": 0.05846304000685147,
            "min": 0.033726001060737566,
            "max": 0.11692342803871725,
            "count": 102
        },
        "Basic.Losses.ValueLoss.mean": {
            "value": 0.006257232831558213,
            "min": 0.00039754265172733646,
            "max": 0.0096094421557306,
            "count": 102
        },
        "Basic.Losses.ValueLoss.sum": {
            "value": 0.012514465663116425,
            "min": 0.00062532824176742,
            "max": 0.024729969668745376,
            "count": 102
        },
        "Basic.Policy.LearningRate.mean": {
            "value": 2.795020943359364e-06,
            "min": 2.795020943359364e-06,
            "max": 0.00029760000079999996,
            "count": 102
        },
        "Basic.Policy.LearningRate.sum": {
            "value": 5.590041886718728e-06,
            "min": 5.590041886718728e-06,
            "max": 0.0008426323433413086,
            "count": 102
        },
        "Basic.Policy.Epsilon.mean": {
            "value": 0.100931640625,
            "min": 0.100931640625,
            "max": 0.19920000000000002,
            "count": 102
        },
        "Basic.Policy.Epsilon.sum": {
            "value": 0.20186328125,
            "min": 0.19840000000000002,
            "max": 0.58087744140625,
            "count": 102
        },
        "Basic.Policy.Beta.mean": {
            "value": 5.6488867187499833e-05,
            "min": 5.6488867187499833e-05,
            "max": 0.0049600799999999995,
            "count": 102
        },
        "Basic.Policy.Beta.sum": {
            "value": 0.00011297773437499967,
            "min": 0.00011297773437499967,
            "max": 0.014045784326171875,
            "count": 102
        },
        "Basic.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        },
        "Basic.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1618619664",
        "python_version": "3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\user\\Anaconda3\\envs\\rlnav\\Scripts\\mlagents-learn rlnav/configs/PPO_512.yaml --env=C:\\Users\\user\\Desktop\\RLNav\\NavigationEnvironments\\P0\\Jump93\\Env.exe --run-id=0_Pipeline\\Jump93\\PPO_512\\Run_0 --time-scale=20 --base-port=6100 --width=480 --height=480 --torch-device=cuda",
        "mlagents_version": "0.25.0",
        "mlagents_envs_version": "0.25.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.8.1",
        "numpy_version": "1.19.2",
        "end_time_seconds": "1618623439"
    },
    "total": 3775.0665126999997,
    "count": 1,
    "self": 2.5862602999995943,
    "children": {
        "run_training.setup": {
            "total": 0.2764945999999999,
            "count": 1,
            "self": 0.2764945999999999
        },
        "TrainerController.start_learning": {
            "total": 3772.2037578,
            "count": 1,
            "self": 2.609470299968507,
            "children": {
                "TrainerController._reset_env": {
                    "total": 12.7087286,
                    "count": 1,
                    "self": 12.7087286
                },
                "TrainerController.advance": {
                    "total": 3756.687315600031,
                    "count": 67340,
                    "self": 2.673102100035976,
                    "children": {
                        "env_step": {
                            "total": 3041.5935536000466,
                            "count": 67340,
                            "self": 2806.3115817000025,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 233.5024461000092,
                                    "count": 67340,
                                    "self": 10.091711499993835,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 223.41073460001536,
                                            "count": 64132,
                                            "self": 92.14797909997426,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 131.2627555000411,
                                                    "count": 64132,
                                                    "self": 131.2627555000411
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.7795258000347083,
                                    "count": 67340,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3758.734968699953,
                                            "count": 67340,
                                            "is_parallel": true,
                                            "self": 1141.8541342999092,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.002406799999999265,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00035860000000020875,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0020481999999990563,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0020481999999990563
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2616.878427600044,
                                                    "count": 67340,
                                                    "is_parallel": true,
                                                    "self": 13.555700700103898,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 116.7743363999648,
                                                            "count": 67340,
                                                            "is_parallel": true,
                                                            "self": 116.7743363999648
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2369.584289600002,
                                                            "count": 67340,
                                                            "is_parallel": true,
                                                            "self": 2369.584289600002
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 116.96410089997278,
                                                            "count": 67340,
                                                            "is_parallel": true,
                                                            "self": 17.04482109995972,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 99.91927980001306,
                                                                    "count": 134680,
                                                                    "is_parallel": true,
                                                                    "self": 99.91927980001306
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 712.4206598999488,
                            "count": 67340,
                            "self": 4.12531489993421,
                            "children": {
                                "process_trajectory": {
                                    "total": 154.12340220001553,
                                    "count": 67340,
                                    "self": 153.67783140001595,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4455707999995866,
                                            "count": 2,
                                            "self": 0.4455707999995866
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 554.171942799999,
                                    "count": 238,
                                    "self": 432.86863529998544,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 121.30330750001355,
                                            "count": 5808,
                                            "self": 121.30330750001355
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.7999999474559445e-06,
                    "count": 1,
                    "self": 2.7999999474559445e-06
                },
                "TrainerController._save_models": {
                    "total": 0.19824050000033822,
                    "count": 1,
                    "self": 0.021411700000498968,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.17682879999983925,
                            "count": 1,
                            "self": 0.17682879999983925
                        }
                    }
                }
            }
        }
    }
}