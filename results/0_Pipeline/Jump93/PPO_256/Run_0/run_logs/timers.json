{
    "name": "root",
    "gauges": {
        "Basic.Policy.Entropy.mean": {
            "value": 1.2815393209457397,
            "min": 1.28144371509552,
            "max": 1.4200680255889893,
            "count": 102
        },
        "Basic.Policy.Entropy.sum": {
            "value": 12938.4208984375,
            "min": 11583.88671875,
            "max": 17425.267578125,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.mean": {
            "value": 165.95,
            "min": 130.75,
            "max": 255.0,
            "count": 102
        },
        "Basic.Environment.EpisodeLength.sum": {
            "value": 9957.0,
            "min": 8011.0,
            "max": 12240.0,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.05527422949671745,
            "min": -0.1549951285123825,
            "max": 0.0888122022151947,
            "count": 102
        },
        "Basic.Policy.ExtrinsicValueEstimate.sum": {
            "value": 3.316453695297241,
            "min": -6.0448102951049805,
            "max": 6.186193466186523,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.mean": {
            "value": 0.2553380265831947,
            "min": -0.2513010643231563,
            "max": 0.4775775272987391,
            "count": 102
        },
        "Basic.Environment.CumulativeReward.sum": {
            "value": 15.320281594991684,
            "min": -9.800741508603096,
            "max": 36.29589207470417,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.mean": {
            "value": 0.2553380265831947,
            "min": -0.2513010643231563,
            "max": 0.4775775272987391,
            "count": 102
        },
        "Basic.Policy.ExtrinsicReward.sum": {
            "value": 15.320281594991684,
            "min": -9.800741508603096,
            "max": 36.29589207470417,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.mean": {
            "value": 0.04405429669421008,
            "min": 0.039596265562067856,
            "max": 0.05791543133758144,
            "count": 102
        },
        "Basic.Losses.PolicyLoss.sum": {
            "value": 0.13216289008263024,
            "min": 0.042949810276089316,
            "max": 0.16584484699918295,
            "count": 102
        },
        "Basic.Losses.ValueLoss.mean": {
            "value": 0.005962052984816384,
            "min": 6.536024164804486e-05,
            "max": 0.010063878102098696,
            "count": 102
        },
        "Basic.Losses.ValueLoss.sum": {
            "value": 0.01788615895444915,
            "min": 0.00013072048329608972,
            "max": 0.030191634306296088,
            "count": 102
        },
        "Basic.Policy.LearningRate.mean": {
            "value": 2.635743652701815e-06,
            "min": 2.635743652701815e-06,
            "max": 0.0002976000008,
            "count": 102
        },
        "Basic.Policy.LearningRate.sum": {
            "value": 7.907230958105445e-06,
            "min": 7.907230958105445e-06,
            "max": 0.0008423543160902343,
            "count": 102
        },
        "Basic.Policy.Epsilon.mean": {
            "value": 0.10087854817708335,
            "min": 0.10087854817708335,
            "max": 0.19920000000000002,
            "count": 102
        },
        "Basic.Policy.Epsilon.sum": {
            "value": 0.30263564453125,
            "min": 0.194769921875,
            "max": 0.580784765625,
            "count": 102
        },
        "Basic.Policy.Beta.mean": {
            "value": 5.38395540364582e-05,
            "min": 5.38395540364582e-05,
            "max": 0.0049600799999999995,
            "count": 102
        },
        "Basic.Policy.Beta.sum": {
            "value": 0.0001615186621093746,
            "min": 0.0001615186621093746,
            "max": 0.014041159804687502,
            "count": 102
        },
        "Basic.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        },
        "Basic.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 102
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1618615764",
        "python_version": "3.8.8 (default, Feb 24 2021, 15:54:32) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\user\\Anaconda3\\envs\\rlnav\\Scripts\\mlagents-learn rlnav/configs/PPO_256.yaml --env=C:\\Users\\user\\Desktop\\RLNav\\NavigationEnvironments\\P0\\Jump93\\Env.exe --run-id=0_Pipeline\\Jump93\\PPO_256\\Run_0 --time-scale=20 --base-port=6490 --width=480 --height=480 --torch-device=cuda",
        "mlagents_version": "0.25.0",
        "mlagents_envs_version": "0.25.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.8.1",
        "numpy_version": "1.19.2",
        "end_time_seconds": "1618619660"
    },
    "total": 3895.4393489999998,
    "count": 1,
    "self": 2.868022099999507,
    "children": {
        "run_training.setup": {
            "total": 0.26257350000000024,
            "count": 1,
            "self": 0.26257350000000024
        },
        "TrainerController.start_learning": {
            "total": 3892.3087534,
            "count": 1,
            "self": 2.5751457000101254,
            "children": {
                "TrainerController._reset_env": {
                    "total": 15.406207799999997,
                    "count": 1,
                    "self": 15.406207799999997
                },
                "TrainerController.advance": {
                    "total": 3874.1175286999896,
                    "count": 67356,
                    "self": 2.775421100094718,
                    "children": {
                        "env_step": {
                            "total": 3050.512355799948,
                            "count": 67356,
                            "self": 2813.715449399925,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 234.9882998999891,
                                    "count": 67356,
                                    "self": 9.949268900017756,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 225.03903099997135,
                                            "count": 64160,
                                            "self": 93.16594819994512,
                                            "children": {
                                                "TorchPolicy.sample_actions": {
                                                    "total": 131.87308280002622,
                                                    "count": 64160,
                                                    "self": 131.87308280002622
                                                }
                                            }
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.8086065000338714,
                                    "count": 67356,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 3876.3613624999816,
                                            "count": 67356,
                                            "is_parallel": true,
                                            "self": 1253.028232799964,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0017703999999998388,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0002953000000012196,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0014750999999986192,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0014750999999986192
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 2623.3313593000175,
                                                    "count": 67356,
                                                    "is_parallel": true,
                                                    "self": 13.434243300084745,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 117.2393095000027,
                                                            "count": 67356,
                                                            "is_parallel": true,
                                                            "self": 117.2393095000027
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 2374.7401857999507,
                                                            "count": 67356,
                                                            "is_parallel": true,
                                                            "self": 2374.7401857999507
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 117.91762069997942,
                                                            "count": 67356,
                                                            "is_parallel": true,
                                                            "self": 17.13387300003403,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 100.7837476999454,
                                                                    "count": 134712,
                                                                    "is_parallel": true,
                                                                    "self": 100.7837476999454
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 820.8297517999468,
                            "count": 67356,
                            "self": 4.119722099938599,
                            "children": {
                                "process_trajectory": {
                                    "total": 155.0603976000068,
                                    "count": 67356,
                                    "self": 154.65265210000666,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4077455000001464,
                                            "count": 2,
                                            "self": 0.4077455000001464
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 661.6496321000014,
                                    "count": 236,
                                    "self": 436.56027309999547,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 225.08935900000597,
                                            "count": 11712,
                                            "self": 225.08935900000597
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.500000053056283e-06,
                    "count": 1,
                    "self": 1.500000053056283e-06
                },
                "TrainerController._save_models": {
                    "total": 0.2098697000001266,
                    "count": 1,
                    "self": 0.02414980000048672,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.1857198999996399,
                            "count": 1,
                            "self": 0.1857198999996399
                        }
                    }
                }
            }
        }
    }
}