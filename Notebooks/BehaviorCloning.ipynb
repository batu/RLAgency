{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_wK2B8JJwsQ",
    "outputId": "34529116-8689-4cf3-9467-58da865821ac"
   },
   "source": [
    "# Reinforcement Learning for Navigation Behavior Cloning Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import torchmetrics\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "from dgl.dataloading import GraphDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rlnav.wrappers import AbsPosOnlyWrapper\n",
    "\n",
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from gym_unity.envs import UnityToMultiGymWrapper \n",
    "from mlagents_envs.side_channel.environment_parameters_channel import EnvironmentParametersChannel\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to Unity environment with package version 1.8.1-preview and communication version 1.4.0\n",
      "[INFO] Connected new brain: Basic?team=0\n",
      "[WARNING] The environment contains multiple observations. You must define allow_multiple_obs=True to receive them all. Otherwise, only the first visual observation (or vector observation ifthere are no visual observations) will be provided in the observation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batua\\anaconda3\\envs\\rlnav2\\lib\\site-packages\\gym\\spaces\\box.py:74: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  \"Box bound precision lowered by casting to {}\".format(self.dtype)\n"
     ]
    }
   ],
   "source": [
    "observation_config = {\n",
    "  \"use_occupancy\": False,\n",
    "  \"use_whiskers\": False,\n",
    "  \"use_depthmap\": False,\n",
    "  \"curriculum_length\":-1\n",
    "}\n",
    "environment_channel = EnvironmentParametersChannel()\n",
    "for key, value in observation_config.items():\n",
    "    environment_channel.set_float_parameter(key, value)\n",
    "\n",
    "env_path = Path(fr\"C:\\Users\\batua\\Desktop\\RLNav\\NavigationEnvironments\\Debug\\Baseline\")\n",
    "unity_env = UnityEnvironment(str(env_path), base_port=5000 + random.randint(0,5000), side_channels=[environment_channel])\n",
    "env = UnityToMultiGymWrapper(unity_env, env_channel=environment_channel)\n",
    "ENV = AbsPosOnlyWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_count=500, random=False, pos_only=True):\n",
    "  done_testing = False\n",
    "  results = []\n",
    "  obs = ENV.reset()\n",
    "\n",
    "  while not done_testing:\n",
    "    if pos_only:\n",
    "      obs = np.array(obs).squeeze()\n",
    "    actions = model(th.tensor(obs)).detach().numpy() if not random else np.random.uniform(low=-1, high=1, size=(32,3))\n",
    "    obs, rews, dones, infos = ENV.step(actions)\n",
    "    for (done, reward) in zip(dones, rews):\n",
    "      if done:\n",
    "        if reward == 1.0:\n",
    "            results.append(1.0)\n",
    "        elif reward == -1.0 or reward == 0.0:\n",
    "            results.append(0.0)\n",
    "      if test_count == len(results):\n",
    "        done_testing = True\n",
    "        break\n",
    "  return sum(results) / len(results)\n",
    "\n",
    "# random_success_rate = test_model(None, test_count=100, random=True)\n",
    "# random_success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Incoming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (25000, 19) (25000, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset_observations = np.load('Data/DebugRandom_obs.npy')\n",
    "dataset_observations = dataset_observations.squeeze()\n",
    "\n",
    "dataset_actions = np.load('Data/DebugRandom_actions.npy')\n",
    "dataset_actions = dataset_actions.squeeze()\n",
    "\n",
    "print(\"Loaded shape:\", dataset_observations.shape, dataset_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "agent_pos = dataset_observations[:, 13:16]\n",
    "goal_pos  = dataset_observations[:, 16:19]\n",
    "\n",
    "ACTIONS = dataset_actions\n",
    "GRAPH_FEATURE_SET = np.stack([agent_pos, goal_pos], axis=1)\n",
    "print(GRAPH_FEATURE_SET.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cloning Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNoGraph(pl.LightningModule): \n",
    "  def __init__(self, in_dim, h_feats=16):\n",
    "    super(BaselineNoGraph, self).__init__()\n",
    "    self.linear_1 = nn.Linear(in_dim, h_feats)\n",
    "    self.linear_2 = nn.Linear(h_feats, h_feats)\n",
    "    self.linear_3 = nn.Linear(h_feats, 3)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.linear_1(x))\n",
    "    x = F.dropout(F.relu(self.linear_2(x)), p=0.1) # To Introduce slight bit of randomess which helps\n",
    "    x = self.linear_3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+\n",
      "|     Modules     | Parameters |\n",
      "+-----------------+------------+\n",
      "| linear_1.weight |    192     |\n",
      "|  linear_1.bias  |     32     |\n",
      "| linear_2.weight |    1024    |\n",
      "|  linear_2.bias  |     32     |\n",
      "| linear_3.weight |     96     |\n",
      "|  linear_3.bias  |     3      |\n",
      "+-----------------+------------+\n",
      "Total Trainable Params: 1379\n",
      "Loss is 4.2e-01 at step 0\n",
      "Loss is 4.2e-02 at step 1000\n",
      "Loss is 6.0e-02 at step 2000\n",
      "Loss is 5.8e-02 at step 3000\n",
      "Loss is 1.4e-01 at step 3000\n",
      "Loss is 1.7e-02 at step 4000\n",
      "Loss is 3.3e-02 at step 5000\n",
      "Loss is 5.3e-02 at step 6000\n",
      "Loss is 1.1e-01 at step 6000\n",
      "Loss is 1.3e-02 at step 7000\n",
      "Loss is 9.4e-03 at step 8000\n",
      "Loss is 2.4e-02 at step 9000\n",
      "Loss is 8.8e-02 at step 9000\n",
      "Loss is 6.1e-03 at step 10000\n",
      "Loss is 9.9e-03 at step 11000\n",
      "Loss is 1.9e-02 at step 12000\n",
      "Loss is 1.1e-01 at step 12000\n",
      "Loss is 6.6e-03 at step 13000\n",
      "Loss is 2.7e-02 at step 14000\n",
      "Loss is 1.9e-02 at step 15000\n",
      "+-----------------+------------+\n",
      "|     Modules     | Parameters |\n",
      "+-----------------+------------+\n",
      "| linear_1.weight |    192     |\n",
      "|  linear_1.bias  |     32     |\n",
      "| linear_2.weight |    1024    |\n",
      "|  linear_2.bias  |     32     |\n",
      "| linear_3.weight |     96     |\n",
      "|  linear_3.bias  |     3      |\n",
      "+-----------------+------------+\n",
      "Total Trainable Params: 1379\n",
      "Loss is 3.9e-01 at step 0\n",
      "Loss is 6.0e-02 at step 1000\n",
      "Loss is 6.2e-02 at step 2000\n",
      "Loss is 4.1e-02 at step 3000\n",
      "Loss is 1.1e-01 at step 3000\n",
      "Loss is 1.3e-02 at step 4000\n",
      "Loss is 3.0e-02 at step 5000\n",
      "Loss is 5.7e-02 at step 6000\n",
      "Loss is 1.0e-01 at step 6000\n",
      "Loss is 9.8e-03 at step 7000\n",
      "Loss is 2.8e-02 at step 8000\n",
      "Loss is 3.3e-02 at step 9000\n",
      "Loss is 8.5e-02 at step 9000\n",
      "Loss is 6.3e-03 at step 10000\n",
      "Loss is 2.4e-02 at step 11000\n",
      "Loss is 1.7e-02 at step 12000\n",
      "Loss is 1.1e-01 at step 12000\n",
      "Loss is 1.8e-02 at step 13000\n",
      "Loss is 1.7e-02 at step 14000\n",
      "Loss is 1.6e-02 at step 15000\n",
      "+-----------------+------------+\n",
      "|     Modules     | Parameters |\n",
      "+-----------------+------------+\n",
      "| linear_1.weight |    192     |\n",
      "|  linear_1.bias  |     32     |\n",
      "| linear_2.weight |    1024    |\n",
      "|  linear_2.bias  |     32     |\n",
      "| linear_3.weight |     96     |\n",
      "|  linear_3.bias  |     3      |\n",
      "+-----------------+------------+\n",
      "Total Trainable Params: 1379\n",
      "Loss is 4.2e-01 at step 0\n",
      "Loss is 4.4e-02 at step 1000\n",
      "Loss is 5.5e-02 at step 2000\n",
      "Loss is 8.9e-02 at step 3000\n",
      "Loss is 1.3e-01 at step 3000\n",
      "Loss is 3.2e-02 at step 4000\n",
      "Loss is 3.4e-02 at step 5000\n",
      "Loss is 3.4e-02 at step 6000\n",
      "Loss is 1.1e-01 at step 6000\n",
      "Loss is 9.7e-03 at step 7000\n",
      "Loss is 2.5e-02 at step 8000\n",
      "Loss is 3.2e-02 at step 9000\n",
      "Loss is 1.0e-01 at step 9000\n",
      "Loss is 6.0e-03 at step 10000\n",
      "Loss is 2.9e-02 at step 11000\n",
      "Loss is 1.4e-02 at step 12000\n",
      "Loss is 1.7e-01 at step 12000\n",
      "Loss is 2.4e-02 at step 13000\n",
      "Loss is 2.2e-02 at step 14000\n",
      "Loss is 1.6e-02 at step 15000\n",
      "+-----------------+------------+\n",
      "|     Modules     | Parameters |\n",
      "+-----------------+------------+\n",
      "| linear_1.weight |    192     |\n",
      "|  linear_1.bias  |     32     |\n",
      "| linear_2.weight |    1024    |\n",
      "|  linear_2.bias  |     32     |\n",
      "| linear_3.weight |     96     |\n",
      "|  linear_3.bias  |     3      |\n",
      "+-----------------+------------+\n",
      "Total Trainable Params: 1379\n",
      "Loss is 3.9e-01 at step 0\n",
      "Loss is 6.0e-02 at step 1000\n",
      "Loss is 4.7e-02 at step 2000\n",
      "Loss is 5.9e-02 at step 3000\n",
      "Loss is 1.1e-01 at step 3000\n",
      "Loss is 3.6e-02 at step 4000\n",
      "Loss is 3.5e-02 at step 5000\n",
      "Loss is 3.0e-02 at step 6000\n",
      "Loss is 9.0e-02 at step 6000\n",
      "Loss is 1.0e-02 at step 7000\n",
      "Loss is 2.9e-02 at step 8000\n",
      "Loss is 4.6e-02 at step 9000\n",
      "Loss is 8.1e-02 at step 9000\n",
      "Loss is 8.6e-03 at step 10000\n",
      "Loss is 1.1e-02 at step 11000\n",
      "Loss is 2.8e-02 at step 12000\n",
      "Loss is 7.9e-02 at step 12000\n",
      "Loss is 8.9e-03 at step 13000\n",
      "Loss is 1.8e-02 at step 14000\n",
      "Loss is 1.7e-02 at step 15000\n",
      "+-----------------+------------+\n",
      "|     Modules     | Parameters |\n",
      "+-----------------+------------+\n",
      "| linear_1.weight |    192     |\n",
      "|  linear_1.bias  |     32     |\n",
      "| linear_2.weight |    1024    |\n",
      "|  linear_2.bias  |     32     |\n",
      "| linear_3.weight |     96     |\n",
      "|  linear_3.bias  |     3      |\n",
      "+-----------------+------------+\n",
      "Total Trainable Params: 1379\n",
      "Loss is 3.8e-01 at step 0\n",
      "Loss is 3.4e-02 at step 1000\n",
      "Loss is 4.5e-02 at step 2000\n",
      "Loss is 7.4e-02 at step 3000\n",
      "Loss is 9.2e-02 at step 3000\n",
      "Loss is 1.6e-02 at step 4000\n",
      "Loss is 2.7e-02 at step 5000\n",
      "Loss is 3.8e-02 at step 6000\n",
      "Loss is 9.2e-02 at step 6000\n",
      "Loss is 2.0e-02 at step 7000\n",
      "Loss is 1.9e-02 at step 8000\n",
      "Loss is 2.3e-02 at step 9000\n",
      "Loss is 9.1e-02 at step 9000\n",
      "Loss is 2.7e-02 at step 10000\n",
      "Loss is 1.8e-02 at step 11000\n",
      "Loss is 2.1e-02 at step 12000\n",
      "Loss is 9.9e-02 at step 12000\n",
      "Loss is 1.1e-02 at step 13000\n",
      "Loss is 2.7e-02 at step 14000\n",
      "Loss is 1.8e-02 at step 15000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dropout_results = []\n",
    "\n",
    "baseline_observations_t = th.tensor(GRAPH_FEATURE_SET.reshape(-1,6)) \n",
    "baseline_actions_t = th.tensor(dataset_actions)\n",
    "\n",
    "dataset = TensorDataset(baseline_observations_t, baseline_actions_t) # create your datset\n",
    "dataloader = DataLoader(dataset, batch_size=8) # create your dataloader\n",
    "\n",
    "for _ in range(5):\n",
    "  model = BaselineNoGraph(6, 32)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "  count_parameters(model)\n",
    "  for epoch in range(5):\n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "      pred = model(x)\n",
    "      loss = F.mse_loss(pred, y)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if i % 1000 == 0:\n",
    "        print(f\"Loss is {loss.item():.1e} at step {epoch * 3000 + i}\")\n",
    "  result = test_model(model)\n",
    "  baseline_dropout_results.append(result)\n",
    "baseline_dropout_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8352, 0.1562183087861343)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results = np.array(baseline_results)\n",
    "baseline_results.mean(), baseline_results.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9800000000000001, 0.03999999999999999)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_dropout_results = np.array(baseline_dropout_results)\n",
    "baseline_dropout_results.mean(), baseline_dropout_results.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "agent_pos = dataset_observations[:, 13:16]\n",
    "goal_pos  = dataset_observations[:, 16:19]\n",
    "\n",
    "GRAPH_FEATURE_SET = np.stack([agent_pos, goal_pos], axis=1)\n",
    "print(GRAPH_FEATURE_SET.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0: Agent\n",
      "Node 1: Goal\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "jsonstr = \"\"\"{\"SourceNodes\":[0],\"DestinationNodes\":[1],\"NumNodes\":2,\"Features\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0],[1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0]]}\"\"\"\n",
    "jsonGraph = json.loads(jsonstr)\n",
    "\n",
    "source_nodes = jsonGraph[\"SourceNodes\"]\n",
    "destination_nodes = jsonGraph[\"DestinationNodes\"]\n",
    "num_nodes = jsonGraph[\"NumNodes\"]\n",
    "\n",
    "GRAPH_SPECIFICATION = (source_nodes, destination_nodes)\n",
    "def visualize_graph(g):\n",
    "  nx_G = g.to_networkx()\n",
    "  pos = nx.kamada_kawai_layout(nx_G)\n",
    "  pos = nx.planar_layout(nx_G)\n",
    "  nx.draw(nx_G, pos, with_labels=True, node_color=[[.7, .7, .7]])\n",
    "\n",
    "g = dgl.graph(GRAPH_SPECIFICATION, num_nodes=num_nodes)\n",
    "visualize_graph(g)\n",
    "\n",
    "print(\"Node 0: Agent\")\n",
    "print(\"Node 1: Goal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import DGLDataset\n",
    "\n",
    "class DebugAgentGoalPosDataset(DGLDataset):\n",
    "  def __init__(self, specification, node_features_array, labels, edge_type=\"goal_to_agent\", add_self_loops=True, add_node_id=True, gpu=True):\n",
    "      self.device = \"cuda:0\" if gpu else \"cpu\"\n",
    "      \n",
    "      self.specification = specification\n",
    "      self.node_features_array = node_features_array\n",
    "      self.labels = th.tensor(labels, device=self.device)\n",
    "      \n",
    "      self.add_self_loops = add_self_loops\n",
    "      self.edge_type = edge_type\n",
    "      self.add_node_id = add_node_id\n",
    "      \n",
    "      super().__init__(name='DebugAgentGoalPosDataset')\n",
    "        \n",
    "  def process(self):\n",
    "    self.graphs = []\n",
    "    \n",
    "    for graph_features in self.node_features_array:\n",
    "      g = dgl.graph(self.specification)\n",
    "      \n",
    "      if self.add_self_loops:\n",
    "        g = dgl.add_self_loop(g)\n",
    "      \n",
    "      if self.edge_type == \"bi_directional\":\n",
    "        g = dgl.to_bidirected(g)\n",
    "      elif self.edge_type == \"goal_to_agent\":\n",
    "        g = dgl.reverse(g)\n",
    "      elif self.edge_type == \"agent_to_goal\":\n",
    "        pass\n",
    "      else:\n",
    "        assert False, f\"{self.edge_type} is not a valid edge type!\"\n",
    "      \n",
    "      if self.device == \"cuda:0\":\n",
    "        g = g.to(self.device)\n",
    "        \n",
    "      if self.add_node_id:\n",
    "        onehot_ids = np.identity(2)\n",
    "        graph_features = np.concatenate([onehot_ids, graph_features], axis=1, dtype=np.float32)\n",
    "        \n",
    "      g.ndata[\"feat\"] = th.tensor(graph_features, device=self.device)\n",
    "      self.graphs.append(g)\n",
    "      \n",
    "\n",
    "  def __getitem__(self, i):\n",
    "    return self.graphs[i], self.labels[i]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(edge_type, add_node_id=True, add_self_loops=True, batch_size=8, overfit_optimization=False, gpu=True):\n",
    "  \n",
    "  \n",
    "  node_features_array = GRAPH_FEATURE_SET[:batch_size + 1] if overfit_optimization else GRAPH_FEATURE_SET \n",
    "  dataset = DebugAgentGoalPosDataset(specification=GRAPH_SPECIFICATION, \n",
    "                                     node_features_array=node_features_array, \n",
    "                                     labels=ACTIONS,\n",
    "                                     gpu=gpu,\n",
    "                                     edge_type=edge_type, \n",
    "                                     add_node_id=add_node_id,\n",
    "                                     add_self_loops=add_self_loops)\n",
    "\n",
    "  num_examples = len(dataset)\n",
    "  num_train = int(num_examples * 0.9)\n",
    "\n",
    "  train_sampler = SubsetRandomSampler(th.arange(num_train),)\n",
    "  test_sampler = SubsetRandomSampler(th.arange(num_train, num_examples))\n",
    "\n",
    "  train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "  test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "  \n",
    "  return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseGNN(pl.LightningModule):\n",
    "  def __init__(self, in_dim, h_feats=16, aggregation_method=\"node\", residual=False, linear_output=False, linear_input=False, learning_rate=0.001):\n",
    "    super(BaseGNN, self).__init__()\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "    return optimizer\n",
    "      \n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "    x, y = train_batch\n",
    "    pred = self(x, x.ndata['feat'])\n",
    "    loss = F.mse_loss(pred, y)\n",
    "    self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return {\"loss\":loss}\n",
    "\n",
    "  def validation_step(self, val_batch, batch_idx):\n",
    "    x, y = val_batch\n",
    "\n",
    "    pred = self(x, x.ndata['feat'])\n",
    "    loss = F.mse_loss(pred, y)\n",
    "\n",
    "    self.log(\"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "    return {\"val_loss\":loss}\n",
    "  \n",
    "  def get_agent_nodes(self, g, agent_index=0):\n",
    "    \"\"\"\n",
    "      node_count:int the number of nodes in each of the graph. We assume this is the same.\n",
    "      example agent_subgraph_idxs if we assume agent_index=0\n",
    "      [ 0,  2,  4,  6,  8, 10, 12, 14] \n",
    "      https://docs.dgl.ai/generated/dgl.batch.html\n",
    "    \"\"\"\n",
    "    batch_num_nodes = set(g.batch_num_nodes())\n",
    "    assert len(batch_num_nodes) != 1, \"The graphs in the batch have different number of nodes.\"\n",
    "    \n",
    "    node_count = batch_num_nodes.pop()\n",
    "    agent_subgraph_idxs = th.arange(agent_index, node_count * g.batch_size, step=node_count, device=self.device)\n",
    "\n",
    "    batched_agent_nodes = dgl.node_subgraph(g, agent_subgraph_idxs)\n",
    "    return batched_agent_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerGCN(BaseGNN):\n",
    "  def __init__(self, in_dim, h_feats=16, aggregation_method=\"node\", residual=False, linear_output=False, linear_input=False, learning_rate=0.001):\n",
    "    super(SingleLayerGCN, self).__init__(\n",
    "      in_dim, \n",
    "      h_feats, \n",
    "      aggregation_method, \n",
    "      residual, \n",
    "      linear_output, \n",
    "      linear_input, \n",
    "      learning_rate\n",
    "    )\n",
    "    self.learning_rate = learning_rate\n",
    "    self.aggregation_method = aggregation_method\n",
    "    self.residual = residual\n",
    "    \n",
    "    self.conv1 = GraphConv(in_dim, 3, allow_zero_in_degree=True)\n",
    "\n",
    "  def forward(self, g, x):\n",
    "    if self.residual:\n",
    "      x += self.conv1(g, x)\n",
    "    else:\n",
    "      x = self.conv1(g, x)\n",
    "      \n",
    "    g.ndata[\"hidden\"] = x\n",
    "    agent_nodes = self.get_agent_nodes(g, 0)\n",
    "    x = agent_nodes.ndata[\"hidden\"]    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregateGCN(BaseGNN): \n",
    "  def __init__(self, in_dim, h_feats=16, num_layers=3, aggregation_method=\"node\", residual=False, linear_output=False, linear_input=False, learning_rate=0.001):\n",
    "    super(AggregateGCN, self).__init__(\n",
    "      in_dim, \n",
    "      h_feats, \n",
    "      aggregation_method, \n",
    "      residual, \n",
    "      linear_output, \n",
    "      linear_input, \n",
    "      learning_rate\n",
    "    )\n",
    "    self.learning_rate = learning_rate\n",
    "    self.aggregation_method = aggregation_method\n",
    "    self.linear_output=linear_output\n",
    "    self.linear_input=linear_input\n",
    "    self.residual = residual\n",
    "    if residual and not (linear_input and linear_output):\n",
    "      raise Exception(\"When residual, linear_input and linear_output need to be True.\")\n",
    "    \n",
    "    if self.linear_input:\n",
    "      self.linear_in = nn.Linear(in_dim, h_feats)\n",
    "      self.conv1 = GraphConv(h_feats, h_feats, allow_zero_in_degree=True)\n",
    "    else:\n",
    "      self.conv1 = GraphConv(in_dim, h_feats, allow_zero_in_degree=True)\n",
    "      \n",
    "    self.conv2 = GraphConv(h_feats, h_feats, allow_zero_in_degree=True)\n",
    "    \n",
    "    if not self.linear_output:\n",
    "      self.conv3 = GraphConv(h_feats, 3, allow_zero_in_degree=True)\n",
    "    else:\n",
    "      self.conv3 = GraphConv(h_feats, h_feats, allow_zero_in_degree=True)\n",
    "      self.linear_out1 = nn.Linear(h_feats, 3)\n",
    "      self.linear_out2 = nn.Linear(3, 3)\n",
    "  \n",
    "  def forward(self, g, x):\n",
    "    if self.linear_input:\n",
    "      x = F.relu(self.linear_in(x))\n",
    "      \n",
    "    if not self.residual:\n",
    "      x = F.relu(self.conv1(g, x))\n",
    "      x = F.relu(self.conv2(g, x))\n",
    "      x = F.relu(self.conv3(g, x))\n",
    "    else:\n",
    "      x += F.relu(self.conv1(g, x))\n",
    "      x += F.relu(self.conv2(g, x))\n",
    "      x += F.relu(self.conv3(g, x))\n",
    "\n",
    "    g.ndata[\"hidden\"] = x\n",
    "    agent_nodes = self.get_agent_nodes(g, 0)\n",
    "    x = agent_nodes.ndata[\"hidden\"]    \n",
    "          \n",
    "    if self.linear_output:\n",
    "      x = F.relu(self.linear_out1(x)) # non_linearity\n",
    "      x = self.linear_out2(x) # can't have activation \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(BaseGNN):\n",
    "  def __init__(self, in_dim, h_feats=16, num_layers=3, aggregation_method=\"node\", residual=False, linear_output=False, linear_input=False, learning_rate=0.001):\n",
    "    super(GCNLayer, self).__init__(\n",
    "      in_dim, \n",
    "      h_feats, \n",
    "      aggregation_method, \n",
    "      residual, \n",
    "      linear_output, \n",
    "      linear_input, \n",
    "      learning_rate\n",
    "    )\n",
    "    self.learning_rate = learning_rate\n",
    "    self.aggregation_method = aggregation_method\n",
    "    self.linear_output=linear_output\n",
    "    self.linear_input=linear_input\n",
    "    self.residual = residual\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    if residual and not (linear_input and linear_output):\n",
    "      raise Exception(\"When residual, linear_input and linear_output need to be True.\")\n",
    "    \n",
    "    self.linear_in = nn.Linear(in_dim, h_feats)\n",
    "    self.convs = nn.ModuleList([GraphConv(h_feats, h_feats, allow_zero_in_degree=True) \n",
    "                                for _ in range(self.num_layers)])\n",
    "    self.one_conv = GraphConv(h_feats, h_feats, allow_zero_in_degree=True)\n",
    "    self.linear_out1 = nn.Linear(h_feats, 3)\n",
    "    self.linear_out2 = nn.Linear(3, 3)\n",
    "  \n",
    "  def forward(self, g, x):\n",
    "    x = F.relu(self.linear_in(x))\n",
    "\n",
    "    for layer in self.convs:\n",
    "      x = x + F.relu(layer(g, x)) if self.residual else F.relu(layer(g, x))\n",
    "\n",
    "    g.ndata[\"hidden\"] = x\n",
    "    agent_nodes = self.get_agent_nodes(g, 0)\n",
    "    \n",
    "    \n",
    "    x = agent_nodes.ndata[\"hidden\"]    \n",
    "    x = F.relu(self.linear_out1(x)) # non_linearity\n",
    "    x = self.linear_out2(x) # can't have activation \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 6.7e-01 at step 0\n",
      "Loss is 3.4e-01 at step 100\n",
      "Loss is 3.4e-01 at step 200\n",
      "Loss is 3.4e-01 at step 300\n",
      "Loss is 3.4e-01 at step 400\n",
      "Loss is 3.4e-01 at step 500\n",
      "Loss is 3.4e-01 at step 600\n",
      "Loss is 3.4e-01 at step 700\n",
      "Loss is 3.4e-01 at step 800\n",
      "Loss is 3.4e-01 at step 900\n",
      "Loss is 3.4e-01 at step 1000\n"
     ]
    }
   ],
   "source": [
    "start_over = True\n",
    "if start_over:\n",
    "  train_dataloader, _ = create_dataloaders(edge_type=\"goal_to_agent\", add_self_loops=False, overfit_optimization=True, gpu=False)\n",
    "  overfit_graph, overfit_label = next(iter(train_dataloader))  \n",
    "\n",
    "  model = GCNLayer(5, num_layers=3, linear_input=True, linear_output=True, residual=True)\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.025)\n",
    "\n",
    "for i in range(0, 1001):\n",
    "  pred = model(overfit_graph, overfit_graph.ndata['feat'])\n",
    "  loss = F.mse_loss(pred, overfit_label)\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "\n",
    "  if i % 100 == 0:\n",
    "    print(f\"Loss is {loss.item():.1e} at step {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871],\n",
       "        [-0.2085, -0.0189, -0.1871]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(overfit_graph, overfit_graph.ndata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_perm_graph_batch(specification, edge_type=\"goal_to_agent\", add_self_loops=True, add_node_id=True, gpu=True):\n",
    "  graphs = []\n",
    "  device = \"cuda:0\" if gpu else \"cpu\"\n",
    "  for _ in range(32):\n",
    "    g = dgl.graph(specification)\n",
    "\n",
    "    if add_self_loops:\n",
    "      g = dgl.add_self_loop(g)\n",
    "\n",
    "    if edge_type == \"bi_directional\":\n",
    "      g = dgl.to_bidirected(g)\n",
    "    elif edge_type == \"goal_to_agent\":\n",
    "      g = dgl.reverse(g)\n",
    "    elif edge_type == \"agent_to_goal\":\n",
    "      pass\n",
    "    else:\n",
    "      assert False, f\"{edge_type} is not a valid edge type!\"\n",
    "\n",
    "    if device == \"cuda:0\":\n",
    "      g = g.to(device)\n",
    "\n",
    "    graph_features = np.array([[7, 7, 7],\n",
    "                               [7, 7, 7]])\n",
    "    if add_node_id:\n",
    "      onehot_ids = np.identity(2)\n",
    "      graph_features = np.concatenate([graph_features, onehot_ids], axis=1, dtype=np.float32)\n",
    "\n",
    "    g.ndata[\"feat\"] = th.tensor(graph_features, device=device)\n",
    "    graphs.append(g)\n",
    "  return dgl.batch(graphs)\n",
    "graph_batch = create_perm_graph_batch(GRAPH_SPECIFICATION, add_node_id=True, gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError -529697949] Windows Error 0xe06d7363",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19292/3012130464.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# random_success_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mtest_graph_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19292/3012130464.py\u001b[0m in \u001b[0;36mtest_graph_model\u001b[1;34m(model, test_count)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mgraph_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"feat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"feat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mENV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rlnav2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19292/2715765509.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, g, x)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0magent_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agent_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19292/25727493.py\u001b[0m in \u001b[0;36mget_agent_nodes\u001b[1;34m(self, g, agent_index)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0magent_subgraph_idxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_count\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mbatched_agent_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_subgraph_idxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbatched_agent_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rlnav2\\lib\\site-packages\\dgl\\subgraph.py\u001b[0m in \u001b[0;36mnode_subgraph\u001b[1;34m(graph, nodes, store_ids)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mnids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0minduced_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_process_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0msgi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minduced_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[0minduced_edges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minduced_edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_create_hetero_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstore_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rlnav2\\lib\\site-packages\\dgl\\heterograph_index.py\u001b[0m in \u001b[0;36mnode_subgraph\u001b[1;34m(self, induced_nodes)\u001b[0m\n\u001b[0;32m    801\u001b[0m         \"\"\"\n\u001b[0;32m    802\u001b[0m         \u001b[0mvids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dgl_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnodes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minduced_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_CAPI_DGLHeteroVertexSubgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0medge_subgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minduced_edges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\rlnav2\\lib\\site-packages\\dgl\\_ffi\\_ctypes\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[0;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError -529697949] Windows Error 0xe06d7363"
     ]
    }
   ],
   "source": [
    "def test_graph_model(model, test_count=500):\n",
    "  done_testing = False\n",
    "  results = []\n",
    "  graph_batch = create_perm_graph_batch(GRAPH_SPECIFICATION, add_node_id=True, gpu=False)  \n",
    "\n",
    "  obs = ENV.reset()\n",
    "  while not done_testing:\n",
    "    obs = np.array(obs).squeeze()\n",
    "    \n",
    "    graph_batch.ndata[\"feat\"][:,:3] = th.tensor(obs.reshape(64, 3))\n",
    "    actions = model(graph_batch, graph_batch.ndata[\"feat\"]).detach().numpy()\n",
    "    \n",
    "    obs, rews, dones, infos = ENV.step(actions)\n",
    "    for (done, reward) in zip(dones, rews):\n",
    "      if done:\n",
    "        if reward == 1.0:\n",
    "            results.append(1.0)\n",
    "        elif reward == -1.0 or reward == 0.0:\n",
    "            results.append(0.0)\n",
    "      if test_count == len(results):\n",
    "        done_testing = True\n",
    "        break\n",
    "  return sum(results) / len(results)\n",
    "\n",
    "# random_success_rate = test_model(None, test_count=100, random=True)\n",
    "# random_success_rate\n",
    "\n",
    "test_graph_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AggregateGCN(\n",
       "  (linear_in): Linear(in_features=5, out_features=16, bias=True)\n",
       "  (conv1): GraphConv(in=16, out=16, normalization=both, activation=None)\n",
       "  (conv2): GraphConv(in=16, out=16, normalization=both, activation=None)\n",
       "  (conv3): GraphConv(in=16, out=16, normalization=both, activation=None)\n",
       "  (linear_out1): Linear(in_features=16, out_features=3, bias=True)\n",
       "  (linear_out2): Linear(in_features=3, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fulldataset Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11856... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.45MB of 0.45MB uploaded (0.05MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">Test</strong>: <a href=\"https://wandb.ai/batu/GNN_Supervised/runs/2332ad5o\" target=\"_blank\">https://wandb.ai/batu/GNN_Supervised/runs/2332ad5o</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211122_135015-2332ad5o\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/batu/GNN_Supervised/runs/2j4q3p12\" target=\"_blank\">Test</a></strong> to <a href=\"https://wandb.ai/batu/GNN_Supervised\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type      | Params\n",
      "------------------------------------------\n",
      "0 | linear_in   | Linear    | 96    \n",
      "1 | conv1       | GraphConv | 272   \n",
      "2 | conv2       | GraphConv | 272   \n",
      "3 | conv3       | GraphConv | 272   \n",
      "4 | linear_out1 | Linear    | 51    \n",
      "5 | linear_out2 | Linear    | 12    \n",
      "------------------------------------------\n",
      "975       Trainable params\n",
      "0         Non-trainable params\n",
      "975       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfd5363ca41401db7abccfe9c8271f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 26380... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.46MB of 0.46MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▁▁▁▂▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▁▃▁▄▁▄▁▁▁▁▂▂▂▂▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▄▄▅▄▄▄▄▄▄▃▃▃▃▄▃▃▃▂▃▃▃▃▃▃▂▃▃▃▂▂▃▃▃▃▂▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>train_loss_epoch</td><td>0.06349</td></tr><tr><td>train_loss_step</td><td>0.07242</td></tr><tr><td>trainer/global_step</td><td>7039</td></tr><tr><td>val_loss_epoch</td><td>0.07856</td></tr><tr><td>val_loss_step</td><td>0.03439</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">Test</strong>: <a href=\"https://wandb.ai/batu/GNN_Supervised/runs/2j4q3p12\" target=\"_blank\">https://wandb.ai/batu/GNN_Supervised/runs/2j4q3p12</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20211122_135125-2j4q3p12\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n",
    "experiment_name = \"OneTrainable\"\n",
    "config = {\n",
    "  \"edge_type\": \"goal_to_agent\",\n",
    "  \"self_loop\": True,\n",
    "  \"hidden_dim\": 16,\n",
    "  \"learning_rate\":0.001,\n",
    "  \"node_id\":True,\n",
    "  \"input_dim\":5,\n",
    "  \"linear_output\":True,\n",
    "  \"linear_input\":True,\n",
    "  \"residual\":True,\n",
    "  \"aggregation_method\":\"node\",\n",
    "  \"batch_size\":64,\n",
    "  \"model_type\":AggregateGCN, #GCNLayer  ##SingleLayerGCN \n",
    "#   \"num_layers\":3,\n",
    "  \"activation\":\"relu\"\n",
    "}\n",
    "\n",
    "hyperparams_1 = [\"agent_to_goal\"]\n",
    "hyperparams_2 = [True]\n",
    "hyperparams_3 = [0]\n",
    "\n",
    "for _ in range(1):\n",
    "  for edge_type in hyperparams_1:\n",
    "    for residual in hyperparams_2:\n",
    "      for num_layers in hyperparams_3:\n",
    "#         config[\"edge_type\"] = edge_type \n",
    "#         config[\"residual\"] = residual \n",
    "#         config[\"num_layers\"] = num_layers \n",
    "\n",
    "        treatment_name = f\"Test\"\n",
    "\n",
    "        run = wandb.init(project=\"GNN_Supervised\", group=experiment_name, name=treatment_name, config=config, save_code=True)  \n",
    "        wandb_logger = WandbLogger()\n",
    "\n",
    "        train_dataloader, val_dataloader = create_dataloaders(edge_type=config[\"edge_type\"], \n",
    "                                                            add_self_loops=config[\"self_loop\"], \n",
    "                                                            add_node_id=config[\"node_id\"],\n",
    "                                                            batch_size=config[\"batch_size\"],\n",
    "                                                            gpu=True)\n",
    "\n",
    "        trainer = pl.Trainer(gpus=1, max_epochs=20, logger=wandb_logger)\n",
    "        GNN = config[\"model_type\"]\n",
    "        model = GNN(config[\"input_dim\"],\n",
    "                   config[\"hidden_dim\"],\n",
    "                   aggregation_method=config[\"aggregation_method\"],\n",
    "                   linear_input=config[\"linear_input\"],\n",
    "                   linear_output=config[\"linear_output\"],\n",
    "                   residual=config[\"residual\"],\n",
    "                   learning_rate=config[\"learning_rate\"],\n",
    "#                    num_layers=config[\"num_layers\"]\n",
    "                   )\n",
    "\n",
    "        trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)      \n",
    "  #       grid_visualization(model, config, False, log_wandb=True)\n",
    "  #       grid_visualization(model, config, True, log_wandb=True)\n",
    "        wandb.finish()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_model(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "UnityML",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
